chunking:
  chunk_size: 512
  overlap_tokens: 50
  include_header_path: true

embedding:
  device: "cuda"
  model_dim: 768
  token_limit: 512
  dense:
    model_name: "BAAI/bge-base-en-v1.5"
    batch_size: 32
    use_fp16: true
    show_progress_bar: false
  sparse:
    model_name: "prithivida/Splade_PP_en_v1"
    batch_size: 8
    threads: 4

qdrant:
  url: "http://localhost:6333"
  distance_metric: "Cosine"
  grpc_port: 6334
  storage_batch_size: 500

reranker:
  model_name: "BAAI/bge-reranker-v2-m3"
  device: "cpu"
  batch_size: 32
  enabled: true

llm:
  model: "llama3.2"
  temperature: 0.1
  max_tokens: 1000

compression:
  model_name: "microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank"
  compression_ratio: 0.5
  token_limit: null
  device: "cpu"

postgres:
  url: "postgresql+asyncpg://researcher:password@localhost:5432/deep_research"
  pool_size: 10
  max_overflow: 20

redis:
  url: "redis://localhost:6379/0"
  db: 0
  max_connections: 50

searxng:
  api_url: "http://localhost:8080/search"
  timeout: 30

crawl4ai:
  browser_type: "chromium"
  headless: true
  timeout: 30

research:
  default_depth_limit: 3
  max_pages_per_task: 100
  priority_threshold: 0.5
  seed_question_count: 5

synthesis:
  llm_temperature: 0.3
  max_output_tokens: 4000