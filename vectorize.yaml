# Embedding Model Configuration
model_name: "BAAI/bge-base-en-v1.5"
model_dim: 768
device: "cpu"  # Options: "cpu", "cuda"
max_token_limit: 512

# Chunking Parameters
target_chunk_size: 500  # Target size in tokens

# Semantic Chunking Behavior
keep_tables_intact: true      # Keep tables whole if possible
keep_code_blocks_intact: true # Keep code blocks whole if possible
keep_list_items_together: true # Keep list items together
use_sentence_boundaries: true  # Never split mid-sentence
# max_recursion_depth: 3       # Maximum depth for recursive splitting

# Context Enhancement
include_document_context: true      # Add document title/metadata
include_header_path: true           # Add hierarchical section path
include_surrounding_context: true   # Add sentences before/after
# surrounding_sentences_before: 2   # Sentences before current chunk
# surrounding_sentences_after: 1    # Sentences after current chunk

# Entity Extraction (requires spaCy)
extract_entities: true  # Extract named entities (PERSON, ORG, etc.)
# entity_types:         # Which entity types to extract
#   - "PERSON"
#   - "ORG"
#   - "PRODUCT"
#   - "GPE"
#   - "DATE"

# Multi-Representation (for better retrieval)
create_table_descriptions: true  # Natural language descriptions for tables
create_code_descriptions: true   # Natural language descriptions for code

# Qdrant Configuration
qdrant_url: "http://localhost:6333"
collection_name: "sample_chunk"
distance_metric: "Cosine"  # Options: "Cosine", "Euclid", "Dot"

# Optional: Qdrant Cloud API key
# api_key: "your-api-key-here"

# Logging Configuration
log_level: "INFO"  # Options: "DEBUG", "INFO", "WARNING", "ERROR"
# log_file: "vectorize.log"  # Uncomment to log to file