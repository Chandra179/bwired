chunk_size: 256                    # Target chunk size in tokens
overlap_tokens: 30                 # Overlap between chunks
use_sentence_boundaries: true      # Respect sentence boundaries

# Context enrichment
include_header_path: true          # Include header hierarchy in chunks

# Dense embedding configuration
dense_model_name: "BAAI/bge-base-en-v1.5"
device: "cuda"                      # Options: cpu, cuda, mps
embedding_batch_size: 30          # Batch size for dense embeddings
use_fp16: true                     # Use FP16 precision (CUDA only)
show_progress_bar: false           # Show progress during encoding

# Sparse embedding configuration
sparse_model_name: "prithivida/Splade_PP_en_v1"
sparse_batch_size: 5               # Batch size for sparse embeddings
sparse_threads: 2                  # Number of CPU threads

# Model configuration
embedding_token_limit: 512         # Max tokens per chunk
model_dim: 768                     # Dense embedding dimension

# Qdrant configuration
qdrant_url: "http://localhost:6333"
collection_name: "markdown_chunks"
distance_metric: "Cosine"
grpc_port: 6334
storage_batch_size: 500            # Batch size for storing in Qdrant

# Logging
log_level: "INFO"                  # Options: DEBUG, INFO, WARNING, ERROR